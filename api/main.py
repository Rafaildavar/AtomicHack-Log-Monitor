"""FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ –∂–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–ª–µ–≥–∏, —á—Ç–æ –∏ Telegram –±–æ—Ç.
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Excel –æ—Ç—á–µ—Ç—ã –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ –¥–ª—è –∑–∞—â–∏—Ç—ã.
"""

import logging
import os
import tempfile
import time
import hashlib
import shutil
from typing import Optional, List

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, Form
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É –∫–æ–ª–ª–µ–≥–∏ –∏–∑ core
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from core.services.ml_analyzer import MLLogAnalyzer
from core.services.log_parser import LogParser
from core.services.report_generator import ReportGenerator

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="AtomicHack Log Monitor API",
    description="API –¥–ª—è ML-–∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –ª–æ–≥–∏–∫—É, —á—Ç–æ –∏ Telegram –±–æ—Ç.",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã (–ª–æ–≥–∏–∫–∞ –∫–æ–ª–ª–µ–≥–∏)
ml_analyzer = MLLogAnalyzer(similarity_threshold=0.7)
log_parser = LogParser()
report_generator = ReportGenerator()

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
REPORTS_DIR = os.path.join(os.path.dirname(__file__), 'reports')
UPLOADS_DIR = os.path.join(os.path.dirname(__file__), 'uploads')
os.makedirs(REPORTS_DIR, exist_ok=True)
os.makedirs(UPLOADS_DIR, exist_ok=True)

# –ó–∞–≥—Ä—É–∂–∞–µ–º ML –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤)
logger.info("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ API...")
ml_analyzer._load_model()
logger.info("‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∞–Ω–∞–ª–∏–∑–∞–º")


def generate_log_visualization(logs_df: pd.DataFrame) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π HTML –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª–æ–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏.
    
    Args:
        logs_df: DataFrame —Å –ª–æ–≥–∞–º–∏ (columns: datetime, level, text, filename, line_number)
    
    Returns:
        HTML —Å—Ç—Ä–æ–∫–∞ —Å –≥—Ä–∞—Ñ–∏–∫–æ–º
    """
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        df = logs_df.copy()
        
        # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        if 'datetime' not in df.columns or 'level' not in df.columns:
            logger.warning("–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º")
            return "<div>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞</div>"
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º datetime –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
        df = df.dropna(subset=['datetime'])
        
        if df.empty:
            return "<div>–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞</div>"
        
        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—é
        level_counts = df['level'].value_counts().to_dict()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –∏ —Ü–≤–µ—Ç–∞
        level_order = ["INFO", "WARNING", "ERROR"]
        color_map = {
            "INFO": "#87CEEB",      # Light sky blue
            "WARNING": "#FFD700",    # Gold
            "ERROR": "#FF6347"       # Tomato
        }
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
        df = df[df['level'].isin(level_order)]
        
        if df.empty:
            return "<div>–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è</div>"
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π scatter –≥—Ä–∞—Ñ–∏–∫
        fig = go.Figure()
        
        for level in level_order:
            level_data = df[df['level'] == level]
            if not level_data.empty:
                count = len(level_data)
                fig.add_trace(go.Scatter(
                    x=level_data['datetime'],
                    y=[level] * count,
                    mode='markers',
                    name=f"{level} ({count})",
                    marker=dict(
                        size=10,
                        color=color_map.get(level, "#999999"),
                        opacity=0.8,
                        line=dict(width=1, color="white")
                    ),
                    text=level_data['text'].astype(str),
                    hovertemplate='<b>%{y}</b><br>–í—Ä–µ–º—è: %{x}<br>–°–æ–æ–±—â–µ–Ω–∏–µ: %{text}<extra></extra>'
                ))
        
        # –û–±–Ω–æ–≤–ª—è–µ–º layout
        fig.update_layout(
            title="üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏",
            xaxis_title="–í—Ä–µ–º—è",
            yaxis_title="–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è",
            template="plotly_dark",
            height=400,
            hovermode='closest',
            yaxis=dict(categoryorder="array", categoryarray=level_order),
            plot_bgcolor="#0a0e27",
            paper_bgcolor="#0a0e27",
            font=dict(color="white", family="Arial, sans-serif")
        )
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º HTML
        html = fig.to_html(include_plotlyjs='cdn', config={'responsive': True})
        return html
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
        return f"<div style='color: red;'>–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}</div>"


def generate_timeline_visualization_from_df(logs_df: pd.DataFrame) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Timeline –≥—Ä–∞—Ñ–∏–∫ –æ—Ç –∫–æ–ª–ª–µ–≥–∏ (–∏–∑ graphics.py) –¥–ª—è DataFrame.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç plotly.express –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∫–æ–ª–ª–µ–≥–∏.
    
    Args:
        logs_df: DataFrame —Å –ª–æ–≥–∞–º–∏ (columns: datetime, level, text, source)
    
    Returns:
        HTML —Å—Ç—Ä–æ–∫–∞ —Å –≥—Ä–∞—Ñ–∏–∫–æ–º Timeline
    """
    try:
        df = logs_df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        if 'datetime' not in df.columns or 'level' not in df.columns:
            return "<div>–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Timeline –≥—Ä–∞—Ñ–∏–∫–∞</div>"
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–∫–∞–∫ —É –∫–æ–ª–ª–µ–≥–∏)
        df = df.rename(columns={'datetime': 'time', 'text': 'message'})
        df['time'] = pd.to_datetime(df['time'], errors='coerce')
        df = df.dropna(subset=['time'])
        
        if df.empty:
            return "<div>–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è Timeline</div>"
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ —É—Ä–æ–≤–Ω–µ–π (–∫–∞–∫ —É –∫–æ–ª–ª–µ–≥–∏)
        level_order = ["INFO", "WARNING", "ERROR"]
        df["level"] = pd.Categorical(df["level"], categories=level_order, ordered=True)
        
        # –¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ (–∫–∞–∫ —É –∫–æ–ª–ª–µ–≥–∏)
        color_map = {
            "INFO": "lightskyblue",
            "WARNING": "gold",
            "ERROR": "tomato"
        }
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ (–¢–û–ß–ù–û –ö–ê–ö –£ –ö–û–õ–õ–ï–ì–ò)
        fig = px.scatter(
            df,
            x="time",
            y="level",
            color="level",
            color_discrete_map=color_map,
            hover_data={"message": True, "time": False, "level": False},
            title="üìä Timeline —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏ - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏"
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∫–∞–∫ —É –∫–æ–ª–ª–µ–≥–∏)
        fig.update_traces(marker=dict(size=10, opacity=0.8))
        fig.update_layout(
            xaxis_title="–í—Ä–µ–º—è",
            yaxis_title="–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∞",
            yaxis_categoryorder="array",
            yaxis_categoryarray=level_order,
            legend_title="–¢–∏–ø –ª–æ–≥–∞",
            template="plotly_dark",  # –¢–µ–º–Ω–∞—è —Ç–µ–º–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            height=500,
            plot_bgcolor="#0a0e27",
            paper_bgcolor="#0a0e27",
            font=dict(color="white"),
            hoverlabel=dict(bgcolor="white", font_size=12)
        )
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º HTML
        html = fig.to_html(include_plotlyjs='cdn', config={'responsive': True})
        return html
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Timeline –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
        return f"<div style='color: red;'>–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Timeline: {str(e)}</div>"


def generate_anomaly_graph(results_df: pd.DataFrame, anomalies_df: pd.DataFrame) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∞–Ω–æ–º–∞–ª–∏—è–º–∏ –∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏.
    
    Args:
        results_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        anomalies_df: DataFrame —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º –∞–Ω–æ–º–∞–ª–∏–π
    
    Returns:
        HTML —Å—Ç—Ä–æ–∫–∞ —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º –≥—Ä–∞—Ñ–æ–º
    """
    try:
        import networkx as nx
        from pyvis.network import Network
        import tempfile
        
        if results_df.empty:
            return "<div>–ù–µ—Ç –∞–Ω–æ–º–∞–ª–∏–π –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞</div>"
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ
        G = nx.Graph()
        
        # –ë–µ—Ä–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ä—ã –∞–Ω–æ–º–∞–ª–∏—è-–ø—Ä–æ–±–ª–µ–º–∞
        for _, row in results_df.iterrows():
            anom_id = int(row.get('ID –∞–Ω–æ–º–∞–ª–∏–∏', -1))
            prob_id = int(row.get('ID –ø—Ä–æ–±–ª–µ–º—ã', -1))
            
            if anom_id == -1 or prob_id == -1:
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∞–Ω–æ–º–∞–ª–∏–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è
            try:
                anom_matches = anomalies_df[anomalies_df['ID –∞–Ω–æ–º–∞–ª–∏–∏'].astype(int) == anom_id]
                prob_matches = anomalies_df[anomalies_df['ID –ø—Ä–æ–±–ª–µ–º—ã'].astype(int) == prob_id]
                
                anom_text = anom_matches['–ê–Ω–æ–º–∞–ª–∏—è'].values[0] if len(anom_matches) > 0 else 'Unknown'
                prob_text = prob_matches['–ü—Ä–æ–±–ª–µ–º–∞'].values[0] if len(prob_matches) > 0 else 'Unknown'
            except Exception:
                anom_text = 'Unknown'
                prob_text = 'Unknown'
            
            anom_label = f"Anom {anom_id}: {str(anom_text)[:30]}..."
            prob_label = f"Prob {prob_id}: {str(prob_text)[:30]}..."
            
            # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã –∏ —Ä–µ–±—Ä–∞
            G.add_node(anom_label, node_type="anomaly")
            G.add_node(prob_label, node_type="problem")
            G.add_edge(anom_label, prob_label)
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é PyVis
        net = Network(
            height="500px",
            width="100%",
            bgcolor="#0a0e27",
            font_color="white",
            directed=False
        )
        
        net.from_nx(G)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–Ω–µ—à–Ω–µ–≥–æ –≤–∏–¥–∞
        net.set_options("""
        {
          "physics": {
            "enabled": true,
            "barnesHut": {
              "gravitationalConstant": -2000,
              "centralGravity": 0.3,
              "springLength": 150,
              "springConstant": 0.04
            }
          },
          "nodes": {
            "font": {"size": 16, "face": "Arial"},
            "scaling": {"min": 20, "max": 40}
          },
          "edges": {
            "color": {"color": "#00D4FF", "opacity": 0.6},
            "smooth": true
          }
        }
        """)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, dir=REPORTS_DIR) as f:
            temp_path = f.name
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ
        net.save_graph(temp_path)
        
        # –ß–∏—Ç–∞–µ–º HTML
        with open(temp_path, 'r', encoding='utf-8') as f:
            html = f.read()
        
        # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª
        try:
            os.remove(temp_path)
        except:
            pass
        
        return html
        
    except ImportError:
        logger.error("–û—à–∏–±–∫–∞: networkx –∏–ª–∏ pyvis –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        return "<div style='color: orange;'>GraphX libraries not available</div>"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞: {e}")
        return f"<div style='color: red;'>–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞: {str(e)}</div>"


@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç."""
    return {
        "message": "AtomicHack Log Monitor API",
        "version": "1.0.0",
        "team": "Black Lotus",
        "docs": "/docs",
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API."""
    return {
        "status": "healthy",
        "ml_model": "loaded" if ml_analyzer.model is not None else "not_loaded",
        "services": {
            "ml_analyzer": "ready",
            "log_parser": "ready",
            "report_generator": "ready"
        }
    }


@app.post("/api/v1/analyze")
async def analyze_logs(
    log_file: UploadFile = File(..., description="–§–∞–π–ª —Å –ª–æ–≥–∞–º–∏ (.txt, .log, .zip)"),
    anomalies_file: Optional[UploadFile] = File(None, description="–°–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π (anomalies_problems.csv)"),
    threshold: str = Form("0.7")
):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ML (–ª–æ–≥–∏–∫–∞ –∫–æ–ª–ª–µ–≥–∏).
    
    **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ –∂–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞, —á—Ç–æ –∏ Telegram –±–æ—Ç.**
    
    Args:
        log_file: –§–∞–π–ª —Å –ª–æ–≥–∞–º–∏ (txt, log –∏–ª–∏ zip)
        anomalies_file: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π)
        threshold: –ü–æ—Ä–æ–≥ similarity –¥–ª—è ML-–º–æ–¥–µ–ª–∏ (0.0-1.0)
    
    Returns:
        JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å—Å—ã–ª–∫–æ–π –Ω–∞ Excel –æ—Ç—á–µ—Ç
    """
    temp_dir = tempfile.mkdtemp()
    
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º threshold –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ —á–∏—Å–ª–æ
        try:
            threshold_float = float(threshold)
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ threshold –≤ –¥–æ–ø—É—Å—Ç–∏–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            threshold_float = max(0.0, min(1.0, threshold_float))
        except (ValueError, TypeError):
            threshold_float = 0.7
            logger.warning(f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ threshold: {threshold}, –∏—Å–ø–æ–ª—å–∑—É—é –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ 0.7")
        
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑: {log_file.filename}")
        logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏: {threshold_float}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º file_id —Å—Ä–∞–∑—É
        file_id = hashlib.md5(f"{log_file.filename}_{time.time()}".encode()).hexdigest()
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –æ–¥–∏–Ω —Ä–∞–∑ –≤ –ø–∞–º—è—Ç—å
        content = await log_file.read()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –°–†–ê–ó–£ –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (–∏–∑–±–µ–≥–∞–µ–º –¥–≤–æ–π–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è)
        permanent_path = os.path.join(UPLOADS_DIR, f"{file_id}_{log_file.filename}")
        with open(permanent_path, 'wb') as f:
            f.write(content)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø—É—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–≤–º–µ—Å—Ç–æ temp)
        log_file_path = permanent_path
        logger.info(f"üìÅ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –±—É–¥—É—â–∏—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤: {log_file_path}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã —Å –ª–æ–≥–∞–º–∏
        if log_file.filename.endswith('.zip'):
            logger.info("–ò–∑–≤–ª–µ–∫–∞–µ–º ZIP –∞—Ä—Ö–∏–≤")
            log_files = log_parser.extract_zip(log_file_path, temp_dir)
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–≥-—Ñ–∞–π–ª—ã (–Ω–µ CSV)
            log_files = [f for f in log_files if not f.endswith('anomalies_problems.csv')]
        else:
            log_files = [log_file_path]
        
        # –ü–∞—Ä—Å–∏–º –ª–æ–≥–∏ (–ª–æ–≥–∏–∫–∞ –∫–æ–ª–ª–µ–≥–∏)
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ {len(log_files)} —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤")
        logs_df = log_parser.parse_log_files(log_files)
        
        if logs_df.empty:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ª–æ–≥–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.")
        
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(logs_df)} —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤")
        
        # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        basic_analysis = log_parser.analyze_logs_basic(logs_df)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π
        if anomalies_file:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å: {anomalies_file.filename}")
            anomalies_path = os.path.join(temp_dir, anomalies_file.filename)
            with open(anomalies_path, 'wb') as f:
                content = await anomalies_file.read()
                f.write(content)
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ ZIP –∞—Ä—Ö–∏–≤
            if log_file.filename.lower().endswith('.zip'):
                extracted_anomalies = [f for f in log_parser.extract_zip(log_file_path, temp_dir) 
                                      if f.endswith('anomalies_problems.csv')]
                
                if extracted_anomalies:
                    logger.info(f"–ù–∞–π–¥–µ–Ω —Å–ª–æ–≤–∞—Ä—å –≤ ZIP: {extracted_anomalies[0]}")
                    anomalies_path = extracted_anomalies[0]
                else:
                    anomalies_path = None
            else:
                anomalies_path = None
            
            # –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å –Ω–µ –Ω–∞–π–¥–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
            if not anomalies_path:
                default_anomalies = os.path.join(
                    os.path.dirname(__file__), 
                    '..', 'src', 'bot', 'services', 'anomalies_problems.csv'
                )
                if os.path.exists(default_anomalies):
                    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π")
                    anomalies_path = default_anomalies
                else:
                    raise HTTPException(
                        status_code=400, 
                        detail="–°–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª anomalies_problems.csv"
                    )
        
        # –ß–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π
        anomalies_df = pd.read_csv(anomalies_path, sep=';', encoding='utf-8')
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(anomalies_df)} –∞–Ω–æ–º–∞–ª–∏–π –∏–∑ —Å–ª–æ–≤–∞—Ä—è")
        
        # ML-–∞–Ω–∞–ª–∏–∑ (–õ–û–ì–ò–ö–ê –ö–û–õ–õ–ï–ì–ò –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô)
        ml_analyzer.similarity_threshold = threshold_float
        logger.info(f"–ó–∞–ø—É—Å–∫ ML-–∞–Ω–∞–ª–∏–∑–∞ —Å –ø–æ—Ä–æ–≥–æ–º {threshold_float}")
        results_df = ml_analyzer.analyze_logs_with_ml(logs_df, anomalies_df)
        
        logger.info(f"ML-–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {len(results_df)} –ø—Ä–æ–±–ª–µ–º")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        summary = ml_analyzer.get_analysis_summary(results_df)
        
        # –°–æ–∑–¥–∞–µ–º Excel –æ—Ç—á–µ—Ç (–¢–û–ß–ù–û –¢–ê–ö –ñ–ï –ö–ê–ö –î–õ–Ø –ó–ê–©–ò–¢–´)
        excel_report_path = None
        if not results_df.empty:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ '–°—Ü–µ–Ω–∞—Ä–∏–π' –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å report_generator
            results_df_with_scenario = results_df.copy()
            results_df_with_scenario['–°—Ü–µ–Ω–∞—Ä–∏–π'] = 1  # ID —Å—Ü–µ–Ω–∞—Ä–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º DataFrame –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è report_generator (—Ç–æ—á–Ω–æ –∫–∞–∫ –≤ –±–æ—Ç–µ)
            analysis_results = [{
                'results': results_df_with_scenario.to_dict('records')
            }]
            
            # –°–æ–∑–¥–∞–µ–º Excel –æ—Ç—á–µ—Ç –°–†–ê–ó–£ –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–∏–∑–±–µ–≥–∞–µ–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è)
            excel_filename = f"analysis_report_{file_id}_{log_file.filename}.xlsx"
            excel_report_path = os.path.join(REPORTS_DIR, excel_filename)
            excel_report_path = report_generator.create_excel_report(
                analysis_results, 
                excel_report_path
            )
            logger.info(f"Excel –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {excel_report_path}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        logger.info("–§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")
        response = {
            "status": "success",
            "file_id": file_id,  # ID —Ñ–∞–π–ª–∞ –¥–ª—è –±—É–¥—É—â–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤
            "filename": log_file.filename,
            "analysis": {
                "basic_stats": basic_analysis,
                "ml_results": summary,
                "threshold_used": threshold_float
            },
            "results": results_df.to_dict('records') if not results_df.empty else [],
            "excel_report": f"/api/v1/download/{os.path.basename(excel_report_path)}" if excel_report_path else None,
        }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (–¥–æ 10k —Å—Ç—Ä–æ–∫)
        # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –≥—Ä–∞—Ñ–∏–∫–∏ –º–æ–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ Dashboard
        if len(logs_df) <= 10000:
            logger.info(f"–ì–µ–Ω–µ—Ä–∏—Ä—É—é –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è {len(logs_df)} —Å—Ç—Ä–æ–∫...")
            try:
                response["log_visualization"] = generate_log_visualization(logs_df) if not logs_df.empty else None
                logger.info("–ì—Ä–∞—Ñ–∏–∫ –ª–æ–≥–æ–≤ —Å–æ–∑–¥–∞–Ω")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –ª–æ–≥–æ–≤: {e}")
                response["log_visualization"] = None
            
            try:
                response["anomaly_graph"] = generate_anomaly_graph(results_df, anomalies_df) if not results_df.empty else None
                logger.info("–ì—Ä–∞—Ñ–∏–∫ –∞–Ω–æ–º–∞–ª–∏–π —Å–æ–∑–¥–∞–Ω")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π: {e}")
                response["anomaly_graph"] = None
        else:
            logger.info(f"–ü—Ä–æ–ø—É—Å–∫–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞ ({len(logs_df)} —Å—Ç—Ä–æ–∫)")
            response["log_visualization"] = None
            response["anomaly_graph"] = None
        
        logger.info("–í–æ–∑–≤—Ä–∞—â–∞—é –æ—Ç–≤–µ—Ç –∫–ª–∏–µ–Ω—Ç—É")
        return response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/download/{filename}")
async def download_report(filename: str):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Excel –æ—Ç—á–µ—Ç.
    
    **–§–æ—Ä–º–∞—Ç Excel —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–π –∂–µ, –∫–∞–∫ –¥–ª—è –∑–∞—â–∏—Ç—ã –Ω–∞ —Ö–∞–∫–∞—Ç–æ–Ω–µ.**
    """
    # –ò—â–µ–º —Ñ–∞–π–ª –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ reports
    file_path = os.path.join(REPORTS_DIR, filename)
    
    if not os.path.exists(file_path):
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ reports, –∏—â–µ–º –≤ temp
        file_path = os.path.join(tempfile.gettempdir(), filename)
    
    if not os.path.exists(file_path):
        logger.warning(f"Excel —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filename}")
        raise HTTPException(status_code=404, detail=f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ Excel –æ—Ç—á–µ—Ç–∞: {file_path}")
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


@app.get("/api/v1/anomalies/default")
async def get_default_anomalies():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π."""
    default_anomalies = os.path.join(
        os.path.dirname(__file__), 
        '..', 'src', 'bot', 'services', 'anomalies_problems.csv'
    )
    
    if not os.path.exists(default_anomalies):
        raise HTTPException(status_code=404, detail="–î–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return FileResponse(
        path=default_anomalies,
        filename="anomalies_problems.csv",
        media_type="text/csv"
    )


@app.post("/api/v1/timeline")
async def generate_timeline(
    log_file: UploadFile = File(..., description="–§–∞–π–ª —Å –ª–æ–≥–∞–º–∏ –¥–ª—è Timeline –≥—Ä–∞—Ñ–∏–∫–∞")
):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Timeline –≥—Ä–∞—Ñ–∏–∫ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏ (–∫–æ–¥ –∫–æ–ª–ª–µ–≥–∏ –∏–∑ graphics.py).
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º –≥—Ä–∞—Ñ–∏–∫–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª–æ–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏.
    """
    temp_dir = tempfile.mkdtemp()
    
    try:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ Timeline –¥–ª—è —Ñ–∞–π–ª–∞: {log_file.filename}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        log_file_path = os.path.join(temp_dir, log_file.filename)
        with open(log_file_path, 'wb') as f:
            content = await log_file.read()
            f.write(content)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã —Å –ª–æ–≥–∞–º–∏
        if log_file.filename.endswith('.zip'):
            logger.info("–ò–∑–≤–ª–µ–∫–∞–µ–º ZIP –∞—Ä—Ö–∏–≤ –¥–ª—è Timeline")
            log_files = log_parser.extract_zip(log_file_path, temp_dir)
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–≥-—Ñ–∞–π–ª—ã
            log_files = [f for f in log_files if not f.endswith('anomalies_problems.csv')]
        else:
            log_files = [log_file_path]
        
        # –ü–∞—Ä—Å–∏–º –ª–æ–≥–∏
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ {len(log_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è Timeline")
        logs_df = log_parser.parse_log_files(log_files)
        
        if logs_df.empty:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ª–æ–≥–∏")
        
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(logs_df)} —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤ –¥–ª—è Timeline")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        error_count = len(logs_df[logs_df['level'] == 'ERROR']) if 'level' in logs_df.columns else 0
        warning_count = len(logs_df[logs_df['level'] == 'WARNING']) if 'level' in logs_df.columns else 0
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if error_count == 0 and warning_count == 0:
            logger.info("–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π - –æ—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!")
            success_html = """
            <html>
            <head>
                <style>
                    body {
                        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        min-height: 100vh;
                        margin: 0;
                        font-family: 'Arial', sans-serif;
                    }
                    .success-container {
                        background: white;
                        border-radius: 20px;
                        padding: 60px;
                        text-align: center;
                        box-shadow: 0 20px 60px rgba(0,0,0,0.3);
                        max-width: 600px;
                    }
                    .success-icon {
                        font-size: 100px;
                        margin-bottom: 30px;
                        animation: bounce 1s ease infinite;
                    }
                    @keyframes bounce {
                        0%, 100% { transform: translateY(0); }
                        50% { transform: translateY(-20px); }
                    }
                    .success-title {
                        font-size: 32px;
                        font-weight: bold;
                        color: #10b981;
                        margin-bottom: 20px;
                    }
                    .success-message {
                        font-size: 18px;
                        color: #6b7280;
                        line-height: 1.6;
                    }
                    .stats {
                        margin-top: 30px;
                        padding: 20px;
                        background: #f3f4f6;
                        border-radius: 10px;
                    }
                    .stat-item {
                        font-size: 16px;
                        color: #374151;
                        margin: 10px 0;
                    }
                </style>
            </head>
            <body>
                <div class="success-container">
                    <div class="success-icon">‚úÖ</div>
                    <div class="success-title">–û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!</div>
                    <div class="success-message">
                        –í —ç—Ç–æ–º —Ñ–∞–π–ª–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π.<br>
                        –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ!
                    </div>
                    <div class="stats">
                        <div class="stat-item"><strong>–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤:</strong> """ + str(len(logs_df)) + """</div>
                        <div class="stat-item"><strong>–û—à–∏–±–æ–∫ (ERROR):</strong> 0 ‚úÖ</div>
                        <div class="stat-item"><strong>–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π (WARNING):</strong> 0 ‚úÖ</div>
                        <div class="stat-item"><strong>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö (INFO):</strong> """ + str(len(logs_df[logs_df['level'] == 'INFO']) if 'level' in logs_df.columns else len(logs_df)) + """</div>
                    </div>
                </div>
            </body>
            </html>
            """
            return HTMLResponse(content=success_html)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Timeline –≥—Ä–∞—Ñ–∏–∫ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏/–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        timeline_html = generate_timeline_visualization_from_df(logs_df)
        
        logger.info("Timeline –≥—Ä–∞—Ñ–∏–∫ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω")
        
        return HTMLResponse(content=timeline_html)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Timeline: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/timeline/zip/{filename}")
async def list_zip_contents(filename: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤–Ω—É—Ç—Ä–∏ ZIP –∞—Ä—Ö–∏–≤–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∞–Ω–∞–ª–∏–∑–æ–≤.
    """
    try:
        # –ò—â–µ–º —Ñ–∞–π–ª –≤ reports –∏–ª–∏ temp
        zip_path = None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ reports
        possible_path = os.path.join(REPORTS_DIR, filename)
        if os.path.exists(possible_path):
            zip_path = possible_path
        
        if not zip_path:
            raise HTTPException(status_code=404, detail=f"ZIP —Ñ–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        temp_dir = tempfile.mkdtemp()
        extracted_files = log_parser.extract_zip(zip_path, temp_dir)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ .txt —Ñ–∞–π–ª—ã
        txt_files = [
            os.path.basename(f) for f in extracted_files 
            if f.endswith('.txt') and not f.endswith('anomalies_problems.csv')
        ]
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(txt_files)} —Ñ–∞–π–ª–æ–≤ –≤ {filename}")
        
        return {"files": txt_files}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ ZIP: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/v1/timeline/by-file-id/{file_id}")
async def generate_timeline_by_file_id(file_id: str, selected_file: Optional[str] = None):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Timeline –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è —Ä–∞–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–æ –µ–≥–æ file_id.
    –î–ª—è ZIP –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª —á–µ—Ä–µ–∑ selected_file.
    
    Args:
        file_id: ID —Ñ–∞–π–ª–∞ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        selected_file: (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –∏–º—è —Ñ–∞–π–ª–∞ –≤–Ω—É—Ç—Ä–∏ ZIP –∞—Ä—Ö–∏–≤–∞
    
    Returns:
        HTML —Å Timeline –≥—Ä–∞—Ñ–∏–∫–æ–º
    """
    try:
        logger.info(f"–ó–∞–ø—Ä–æ—Å –Ω–∞ Timeline –¥–ª—è file_id: {file_id}, selected_file: {selected_file}")
        
        # –ò—â–µ–º —Ñ–∞–π–ª –≤ uploads –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        matching_files = [f for f in os.listdir(UPLOADS_DIR) if f.startswith(file_id)]
        
        if not matching_files:
            raise HTTPException(status_code=404, detail=f"–§–∞–π–ª —Å ID {file_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        file_path = os.path.join(UPLOADS_DIR, matching_files[0])
        logger.info(f"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {file_path}")
        
        temp_dir = tempfile.mkdtemp()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã —Å –ª–æ–≥–∞–º–∏
        if file_path.endswith('.zip'):
            logger.info("–ò–∑–≤–ª–µ–∫–∞–µ–º ZIP –∞—Ä—Ö–∏–≤")
            log_files = log_parser.extract_zip(file_path, temp_dir)
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–≥-—Ñ–∞–π–ª—ã
            log_files = [f for f in log_files if not f.endswith('anomalies_problems.csv')]
            
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ–≥–æ
            if selected_file:
                log_files = [f for f in log_files if os.path.basename(f) == selected_file]
                if not log_files:
                    raise HTTPException(status_code=404, detail=f"–§–∞–π–ª {selected_file} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∞—Ä—Ö–∏–≤–µ")
        else:
            log_files = [file_path]
        
        # –ü–∞—Ä—Å–∏–º –ª–æ–≥–∏
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ {len(log_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è Timeline")
        logs_df = log_parser.parse_log_files(log_files)
        
        if logs_df.empty:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ª–æ–≥–∏")
        
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(logs_df)} —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤ –¥–ª—è Timeline")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        error_count = len(logs_df[logs_df['level'] == 'ERROR']) if 'level' in logs_df.columns else 0
        warning_count = len(logs_df[logs_df['level'] == 'WARNING']) if 'level' in logs_df.columns else 0
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if error_count == 0 and warning_count == 0:
            logger.info("–í —Ñ–∞–π–ª–µ –Ω–µ—Ç –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π - –æ—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!")
            success_html = """
            <html>
            <head>
                <style>
                    body {
                        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        min-height: 100vh;
                        margin: 0;
                        font-family: 'Arial', sans-serif;
                    }
                    .success-container {
                        background: white;
                        border-radius: 20px;
                        padding: 60px;
                        text-align: center;
                        box-shadow: 0 20px 60px rgba(0,0,0,0.3);
                        max-width: 600px;
                    }
                    .success-icon {
                        font-size: 100px;
                        margin-bottom: 30px;
                        animation: bounce 1s ease infinite;
                    }
                    @keyframes bounce {
                        0%, 100% { transform: translateY(0); }
                        50% { transform: translateY(-20px); }
                    }
                    .success-title {
                        font-size: 32px;
                        font-weight: bold;
                        color: #10b981;
                        margin-bottom: 20px;
                    }
                    .success-message {
                        font-size: 18px;
                        color: #6b7280;
                        line-height: 1.6;
                    }
                    .stats {
                        margin-top: 30px;
                        padding: 20px;
                        background: #f3f4f6;
                        border-radius: 10px;
                    }
                    .stat-item {
                        font-size: 16px;
                        color: #374151;
                        margin: 10px 0;
                    }
                </style>
            </head>
            <body>
                <div class="success-container">
                    <div class="success-icon">‚úÖ</div>
                    <div class="success-title">–û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!</div>
                    <div class="success-message">
                        –í —ç—Ç–æ–º —Ñ–∞–π–ª–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π.<br>
                        –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ!
                    </div>
                    <div class="stats">
                        <div class="stat-item"><strong>–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤:</strong> """ + str(len(logs_df)) + """</div>
                        <div class="stat-item"><strong>–û—à–∏–±–æ–∫ (ERROR):</strong> 0 ‚úÖ</div>
                        <div class="stat-item"><strong>–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π (WARNING):</strong> 0 ‚úÖ</div>
                        <div class="stat-item"><strong>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö (INFO):</strong> """ + str(len(logs_df[logs_df['level'] == 'INFO']) if 'level' in logs_df.columns else len(logs_df)) + """</div>
                    </div>
                </div>
            </body>
            </html>
            """
            return HTMLResponse(content=success_html)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Timeline –≥—Ä–∞—Ñ–∏–∫ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏/–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        timeline_html = generate_timeline_visualization_from_df(logs_df)
        
        logger.info("Timeline –≥—Ä–∞—Ñ–∏–∫ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –ø–æ file_id")
        
        return HTMLResponse(content=timeline_html)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Timeline –ø–æ file_id: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    
    logger.info("–ó–∞–ø—É—Å–∫ AtomicHack Log Monitor API")
    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–ª–µ–≥–∏ –∏–∑ core/")
    logger.info("–§–æ—Ä–º–∞—Ç Excel –æ—Ç—á–µ—Ç–æ–≤ - –∫–∞–∫ –¥–ª—è –∑–∞—â–∏—Ç—ã —Ö–∞–∫–∞—Ç–æ–Ω–∞")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )

