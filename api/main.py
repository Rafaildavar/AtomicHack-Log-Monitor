"""FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ –∂–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–ª–µ–≥–∏, —á—Ç–æ –∏ Telegram –±–æ—Ç.
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Excel –æ—Ç—á–µ—Ç—ã –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ –¥–ª—è –∑–∞—â–∏—Ç—ã.
"""

import logging
import os
import tempfile
from typing import Optional

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, Form
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É –∫–æ–ª–ª–µ–≥–∏ –∏–∑ core
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from core.services.ml_analyzer import MLLogAnalyzer
from core.services.log_parser import LogParser
from core.services.report_generator import ReportGenerator

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="AtomicHack Log Monitor API",
    description="API –¥–ª—è ML-–∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –ª–æ–≥–∏–∫—É, —á—Ç–æ –∏ Telegram –±–æ—Ç.",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã (–ª–æ–≥–∏–∫–∞ –∫–æ–ª–ª–µ–≥–∏)
ml_analyzer = MLLogAnalyzer(similarity_threshold=0.7)
log_parser = LogParser()
report_generator = ReportGenerator()

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤
REPORTS_DIR = os.path.join(os.path.dirname(__file__), 'reports')
os.makedirs(REPORTS_DIR, exist_ok=True)

# –ó–∞–≥—Ä—É–∂–∞–µ–º ML –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤)
logger.info("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ ML –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ API...")
ml_analyzer._load_model()
logger.info("‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∞–Ω–∞–ª–∏–∑–∞–º")


@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç."""
    return {
        "message": "AtomicHack Log Monitor API",
        "version": "1.0.0",
        "team": "Black Lotus",
        "docs": "/docs",
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API."""
    return {
        "status": "healthy",
        "ml_model": "loaded" if ml_analyzer.model is not None else "not_loaded",
        "services": {
            "ml_analyzer": "ready",
            "log_parser": "ready",
            "report_generator": "ready"
        }
    }


@app.post("/api/v1/analyze")
async def analyze_logs(
    log_file: UploadFile = File(..., description="–§–∞–π–ª —Å –ª–æ–≥–∞–º–∏ (.txt, .log, .zip)"),
    anomalies_file: Optional[UploadFile] = File(None, description="–°–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π (anomalies_problems.csv)"),
    threshold: str = Form("0.7")
):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ML (–ª–æ–≥–∏–∫–∞ –∫–æ–ª–ª–µ–≥–∏).
    
    **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ –∂–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞, —á—Ç–æ –∏ Telegram –±–æ—Ç.**
    
    Args:
        log_file: –§–∞–π–ª —Å –ª–æ–≥–∞–º–∏ (txt, log –∏–ª–∏ zip)
        anomalies_file: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π)
        threshold: –ü–æ—Ä–æ–≥ similarity –¥–ª—è ML-–º–æ–¥–µ–ª–∏ (0.0-1.0)
    
    Returns:
        JSON —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å—Å—ã–ª–∫–æ–π –Ω–∞ Excel –æ—Ç—á–µ—Ç
    """
    temp_dir = tempfile.mkdtemp()
    
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º threshold –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ —á–∏—Å–ª–æ
        try:
            threshold_float = float(threshold)
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ threshold –≤ –¥–æ–ø—É—Å—Ç–∏–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            threshold_float = max(0.0, min(1.0, threshold_float))
        except (ValueError, TypeError):
            threshold_float = 0.7
            logger.warning(f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ threshold: {threshold}, –∏—Å–ø–æ–ª—å–∑—É—é –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ 0.7")
        
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑: {log_file.filename}")
        logger.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏: {threshold_float}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏
        log_file_path = os.path.join(temp_dir, log_file.filename)
        with open(log_file_path, 'wb') as f:
            content = await log_file.read()
            f.write(content)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã —Å –ª–æ–≥–∞–º–∏
        if log_file.filename.endswith('.zip'):
            logger.info("–ò–∑–≤–ª–µ–∫–∞–µ–º ZIP –∞—Ä—Ö–∏–≤")
            log_files = log_parser.extract_zip(log_file_path, temp_dir)
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ª–æ–≥-—Ñ–∞–π–ª—ã (–Ω–µ CSV)
            log_files = [f for f in log_files if not f.endswith('anomalies_problems.csv')]
        else:
            log_files = [log_file_path]
        
        # –ü–∞—Ä—Å–∏–º –ª–æ–≥–∏ (–ª–æ–≥–∏–∫–∞ –∫–æ–ª–ª–µ–≥–∏)
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ {len(log_files)} —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤")
        logs_df = log_parser.parse_log_files(log_files)
        
        if logs_df.empty:
            raise HTTPException(status_code=400, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ª–æ–≥–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.")
        
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(logs_df)} —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤")
        
        # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        basic_analysis = log_parser.analyze_logs_basic(logs_df)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π
        if anomalies_file:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å: {anomalies_file.filename}")
            anomalies_path = os.path.join(temp_dir, anomalies_file.filename)
            with open(anomalies_path, 'wb') as f:
                content = await anomalies_file.read()
                f.write(content)
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ ZIP –∞—Ä—Ö–∏–≤
            if log_file.filename.lower().endswith('.zip'):
                extracted_anomalies = [f for f in log_parser.extract_zip(log_file_path, temp_dir) 
                                      if f.endswith('anomalies_problems.csv')]
                
                if extracted_anomalies:
                    logger.info(f"–ù–∞–π–¥–µ–Ω —Å–ª–æ–≤–∞—Ä—å –≤ ZIP: {extracted_anomalies[0]}")
                    anomalies_path = extracted_anomalies[0]
                else:
                    anomalies_path = None
            else:
                anomalies_path = None
            
            # –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å –Ω–µ –Ω–∞–π–¥–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
            if not anomalies_path:
                default_anomalies = os.path.join(
                    os.path.dirname(__file__), 
                    '..', 'src', 'bot', 'services', 'anomalies_problems.csv'
                )
                if os.path.exists(default_anomalies):
                    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π")
                    anomalies_path = default_anomalies
                else:
                    raise HTTPException(
                        status_code=400, 
                        detail="–°–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª anomalies_problems.csv"
                    )
        
        # –ß–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π
        anomalies_df = pd.read_csv(anomalies_path, sep=';', encoding='utf-8')
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(anomalies_df)} –∞–Ω–æ–º–∞–ª–∏–π –∏–∑ —Å–ª–æ–≤–∞—Ä—è")
        
        # ML-–∞–Ω–∞–ª–∏–∑ (–õ–û–ì–ò–ö–ê –ö–û–õ–õ–ï–ì–ò –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô)
        ml_analyzer.similarity_threshold = threshold_float
        logger.info(f"–ó–∞–ø—É—Å–∫ ML-–∞–Ω–∞–ª–∏–∑–∞ —Å –ø–æ—Ä–æ–≥–æ–º {threshold_float}")
        results_df = ml_analyzer.analyze_logs_with_ml(logs_df, anomalies_df)
        
        logger.info(f"ML-–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {len(results_df)} –ø—Ä–æ–±–ª–µ–º")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        summary = ml_analyzer.get_analysis_summary(results_df)
        
        # –°–æ–∑–¥–∞–µ–º Excel –æ—Ç—á–µ—Ç (–¢–û–ß–ù–û –¢–ê–ö –ñ–ï –ö–ê–ö –î–õ–Ø –ó–ê–©–ò–¢–´)
        excel_report_path = None
        if not results_df.empty:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ '–°—Ü–µ–Ω–∞—Ä–∏–π' –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å report_generator
            results_df_with_scenario = results_df.copy()
            results_df_with_scenario['–°—Ü–µ–Ω–∞—Ä–∏–π'] = 1  # ID —Å—Ü–µ–Ω–∞—Ä–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º DataFrame –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è report_generator (—Ç–æ—á–Ω–æ –∫–∞–∫ –≤ –±–æ—Ç–µ)
            analysis_results = [{
                'results': results_df_with_scenario.to_dict('records')
            }]
            
            excel_report_path = os.path.join(temp_dir, f"analysis_report_{log_file.filename}.xlsx")
            excel_report_path = report_generator.create_excel_report(
                analysis_results, 
                excel_report_path
            )
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –æ—Ç—á–µ—Ç –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–π
            import shutil
            final_excel_path = os.path.join(REPORTS_DIR, os.path.basename(excel_report_path))
            try:
                shutil.copy2(excel_report_path, final_excel_path)
                excel_report_path = final_excel_path
            except Exception:
                # –ï—Å–ª–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—É—Ç—å, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å Excel –≤ reports/, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª")
            logger.info(f"Excel –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {excel_report_path}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            "status": "success",
            "analysis": {
                "basic_stats": basic_analysis,
                "ml_results": summary,
                "threshold_used": threshold_float
            },
            "results": results_df.to_dict('records') if not results_df.empty else [],
            "excel_report": f"/api/v1/download/{os.path.basename(excel_report_path)}" if excel_report_path else None
        }
        
        return response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/v1/download/{filename}")
async def download_report(filename: str):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Excel –æ—Ç—á–µ—Ç.
    
    **–§–æ—Ä–º–∞—Ç Excel —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–π –∂–µ, –∫–∞–∫ –¥–ª—è –∑–∞—â–∏—Ç—ã –Ω–∞ —Ö–∞–∫–∞—Ç–æ–Ω–µ.**
    """
    # –ò—â–µ–º —Ñ–∞–π–ª –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ reports
    file_path = os.path.join(REPORTS_DIR, filename)
    
    if not os.path.exists(file_path):
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ reports, –∏—â–µ–º –≤ temp
        file_path = os.path.join(tempfile.gettempdir(), filename)
    
    if not os.path.exists(file_path):
        logger.warning(f"Excel —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filename}")
        raise HTTPException(status_code=404, detail=f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ Excel –æ—Ç—á–µ—Ç–∞: {file_path}")
    return FileResponse(
        path=file_path,
        filename=filename,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


@app.get("/api/v1/anomalies/default")
async def get_default_anomalies():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π."""
    default_anomalies = os.path.join(
        os.path.dirname(__file__), 
        '..', 'src', 'bot', 'services', 'anomalies_problems.csv'
    )
    
    if not os.path.exists(default_anomalies):
        raise HTTPException(status_code=404, detail="–î–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    return FileResponse(
        path=default_anomalies,
        filename="anomalies_problems.csv",
        media_type="text/csv"
    )


if __name__ == "__main__":
    import uvicorn
    
    logger.info("–ó–∞–ø—É—Å–∫ AtomicHack Log Monitor API")
    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–ª–µ–≥–∏ –∏–∑ core/")
    logger.info("–§–æ—Ä–º–∞—Ç Excel –æ—Ç—á–µ—Ç–æ–≤ - –∫–∞–∫ –¥–ª—è –∑–∞—â–∏—Ç—ã —Ö–∞–∫–∞—Ç–æ–Ω–∞")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )

