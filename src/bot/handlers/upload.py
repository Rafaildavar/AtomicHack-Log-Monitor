"""–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–æ–≤."""

import logging
import os
import zipfile
from typing import Dict

import pandas as pd
from aiogram import Router, F
from aiogram.filters import StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import Message, Document, FSInputFile

from ..keyboards.main import build_main_menu_keyboard
from ..services.log_parser import LogParser
from ..services.analysis_history import SimpleFileAnalyzer
from ..services.ml_log_analyzer import MLLogAnalyzer

logger = logging.getLogger(__name__)

router = Router(name="upload")
file_analyzer = SimpleFileAnalyzer()
log_parser = LogParser()
ml_analyzer = MLLogAnalyzer()


class UploadStates(StatesGroup):
    """–°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤."""
    waiting_for_file = State()


@router.message(F.text == "–ó–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–≥–∏")
async def start_upload_process(message: Message, state: FSMContext) -> None:
    """–ù–∞—á–∏–Ω–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤."""

    await message.answer(
        "üìÅ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ (txt, log, csv –∏–ª–∏ zip –∞—Ä—Ö–∏–≤).\n"
        "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–∞–π–ª—ã —Ä–∞–∑–º–µ—Ä–æ–º –¥–æ 50MB."
    )
    await state.set_state(UploadStates.waiting_for_file)


@router.message(UploadStates.waiting_for_file, F.document)
async def handle_file_upload(message: Message, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª."""

    document = message.document

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    if document.file_size and document.file_size > 50 * 1024 * 1024:
        await message.answer(
            "‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å–∏–º—É–º 50MB).\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∂–∞—Ç—å —Ñ–∞–π–ª –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–µ–Ω—å—à–∏–π."
        )
        return

    await message.answer("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–∞–π–ª... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")

    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file_path = await log_parser._download_file(document, message.bot)

        # –®–ê–ì 1: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ –∞–Ω–æ–º–∞–ª–∏–π
        scenarios_data = {}
        anomalies_files = []

        if file_path.endswith('.zip'):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–π–ª—ã –∏–∑ –∞—Ä—Ö–∏–≤–∞
            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                zip_ref.extractall(os.path.dirname(file_path))

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã anomalies_problems.csv
            extract_dir = os.path.dirname(file_path)
            for root, dirs, files in os.walk(extract_dir):
                for file in files:
                    if file == 'anomalies_problems.csv':
                        scenario_name = os.path.basename(os.path.dirname(os.path.join(root, file)))
                        anomalies_files.append((scenario_name, os.path.join(root, file)))
        else:
            # –î–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–ª–æ–≤–∞—Ä—å –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ
            file_dir = os.path.dirname(file_path)
            anomalies_path = os.path.join(file_dir, 'anomalies_problems.csv')
            if os.path.exists(anomalies_path):
                scenario_name = os.path.basename(file_dir)
                anomalies_files.append((scenario_name, anomalies_path))

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤: {len(anomalies_files)}")

        if not anomalies_files:
            await message.answer(
                "‚ö†Ô∏è –°–ª–æ–≤–∞—Ä–∏ –∞–Ω–æ–º–∞–ª–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ —Ñ–∞–π–ª–µ –µ—Å—Ç—å –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏ anomalies_problems.csv."
            )
            await state.clear()
            return

        # –®–ê–ì 2: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π
        all_results = []

        for scenario_name, anomalies_file in anomalies_files:
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∞–Ω–æ–º–∞–ª–∏–π
                anomalies_dict = pd.read_csv(anomalies_file, sep=';')
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è {scenario_name}: {len(anomalies_dict)} –∞–Ω–æ–º–∞–ª–∏–π")

                # –ù–∞—Ö–æ–¥–∏–º –ª–æ–≥–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
                scenario_logs = []
                if file_path.endswith('.zip'):
                    # –ò—â–µ–º —Ñ–∞–π–ª—ã –∏–∑ —Ç–æ–π –∂–µ –ø–∞–ø–∫–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è
                    for root, dirs, files in os.walk(os.path.dirname(anomalies_file)):
                        for file in files:
                            if file.endswith('.txt') or file.endswith('.log'):
                                log_path = os.path.join(root, file)
                                try:
                                    with open(log_path, 'r', encoding='utf-8') as f:
                                        lines = f.readlines()

                                    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫–∏ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º WARNING/ERROR
                                    for line_num, line in enumerate(lines, 1):
                                        line = line.strip()
                                        if 'WARNING' in line.upper() or 'ERROR' in line.upper():
                                            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏
                                            parts = line.split(' ', 2)
                                            if len(parts) >= 3:
                                                dt, level, text = parts[0], parts[1], parts[2]
                                                scenario_logs.append({
                                                    'datetime': dt,
                                                    'level': level,
                                                    'source': 'unknown',
                                                    'text': text,
                                                    'filename': file,
                                                    'line_number': line_num
                                                })
                                except Exception as e:
                                    logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {log_path}: {e}")
                else:
                    # –û–¥–∏–Ω–æ—á–Ω—ã–π —Ñ–∞–π–ª
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            lines = f.readlines()

                        for line_num, line in enumerate(lines, 1):
                            line = line.strip()
                            if 'WARNING' in line.upper() or 'ERROR' in line.upper():
                                parts = line.split(' ', 2)
                                if len(parts) >= 3:
                                    dt, level, text = parts[0], parts[1], parts[2]
                                    scenario_logs.append({
                                        'datetime': dt,
                                        'level': level,
                                        'source': 'unknown',
                                        'text': text,
                                        'filename': os.path.basename(file_path),
                                        'line_number': line_num
                                    })
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")

                if not scenario_logs:
                    logger.warning(f"–î–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è {scenario_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ WARNING/ERROR —Å—Ç—Ä–æ–∫")
                    continue

                logger.info(f"–ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏—è {scenario_name}: {len(scenario_logs)} —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤")

                # –®–ê–ì 3: –ò—Å–ø–æ–ª—å–∑—É–µ–º ML –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π
                logs_df = pd.DataFrame(scenario_logs)
                scenario_results = ml_analyzer.analyze_logs_with_ml(logs_df, anomalies_dict)

                if not scenario_results.empty:
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ü–µ–Ω–∞—Ä–∏–∏
                    scenario_results['–°—Ü–µ–Ω–∞—Ä–∏–π'] = scenario_name
                    all_results.append(scenario_results)
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(scenario_results)} –ø—Ä–æ–±–ª–µ–º –≤ —Å—Ü–µ–Ω–∞—Ä–∏–∏ {scenario_name}")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è {scenario_name}: {e}")
                continue

        # –°–æ–∑–¥–∞–µ–º Excel –æ—Ç—á–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        if all_results:
            final_results = pd.concat(all_results, ignore_index=True)
            excel_path = file_analyzer.create_excel_report([{
                'file_name': document.file_name,
                'analysis_type': 'ml_anomaly_detection',
                'total_scenarios': len(anomalies_files),
                'total_problems': len(final_results),
                'results': final_results.to_dict('records')
            }])
        else:
            excel_path = None

        if excel_path:
            excel_file = FSInputFile(excel_path)
            await message.answer_document(
                excel_file,
                caption=f"üìä ML –∞–Ω–∞–ª–∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º (Excel) - {len(final_results)} –∞–Ω–æ–º–∞–ª–∏–π"
            )

            await message.answer(
                f"‚úÖ ML –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!\n\n"
                f"üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤: {len(anomalies_files)}\n"
                f"üö® –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(final_results)}\n\n"
                f"Excel —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç:\n"
                f"‚Ä¢ ID –∞–Ω–æ–º–∞–ª–∏–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã\n"
                f"‚Ä¢ –§–∞–π–ª—ã –∏ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫\n"
                f"‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ML –∞–Ω–∞–ª–∏–∑–∞\n"
                f"‚Ä¢ –î–µ—Ç–∞–ª–∏ –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º—ã",
                reply_markup=build_main_menu_keyboard()
            )
        else:
            await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel –æ—Ç—á–µ—Ç–∞.")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}", exc_info=True)
        await message.answer(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
        )
    finally:
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        await state.clear()


@router.message(UploadStates.waiting_for_file)
async def handle_invalid_upload(message: Message) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –æ–∂–∏–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞."""

    await message.answer(
        "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ (txt, log, csv –∏–ª–∏ zip).\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É '–ó–∞–≥—Ä—É–∑–∏—Ç—å –ª–æ–≥–∏' –¥–ª—è –Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞."
    )
